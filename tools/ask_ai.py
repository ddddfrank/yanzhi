import os
import sys
import base64
import io
import re

# ================= Windows ç¼–ç ä¿®å¤ =================
# è§£å†³ PyInstaller æ‰“åŒ…å emoji è¾“å‡ºä¹±ç é—®é¢˜
if sys.platform == 'win32':
    try:
        # å¼ºåˆ¶ stdout/stderr ä½¿ç”¨ UTF-8 ç¼–ç 
        sys.stdout.reconfigure(encoding='utf-8', errors='replace')
        sys.stderr.reconfigure(encoding='utf-8', errors='replace')
    except Exception:
        # Python < 3.7 æˆ–å…¶ä»–æƒ…å†µ
        import codecs
        sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, errors='replace')
        sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, errors='replace')

from openai import OpenAI
from PIL import Image

# ================= è·¯å¾„å·¥å…· =================

def get_app_dir():
    """
    è·å–åº”ç”¨ç¨‹åºæ‰€åœ¨ç›®å½•
    - å¼€å‘æ—¶: è¿”å›è„šæœ¬æ‰€åœ¨ç›®å½•
    - æ‰“åŒ…å: è¿”å› exe æ‰€åœ¨ç›®å½•
    """
    if getattr(sys, 'frozen', False):
        # PyInstaller æ‰“åŒ…å
        return os.path.dirname(sys.executable)
    else:
        # å¼€å‘æ¨¡å¼
        return os.path.dirname(os.path.abspath(__file__))


# ================= ç¯å¢ƒå˜é‡åŠ è½½ =================

def load_env_file(env_path: str = None):
    """
    ä» token.env æ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡ï¼ˆæ”¯æŒ PowerShell æ ¼å¼ï¼‰
    
    :param env_path: env æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸º exe/è„šæœ¬ åŒç›®å½•ä¸‹çš„ token.env
    """
    if env_path is None:
        env_path = os.path.join(get_app_dir(), "token.env")
    
    if not os.path.exists(env_path):
        return
    
    try:
        with open(env_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line or line.startswith('#'):
                    continue
                
                # åŒ¹é… PowerShell æ ¼å¼: $env:VAR_NAME = "value" æˆ– $env:VAR_NAME="value"
                match = re.match(r'\$env:(\w+)\s*=\s*["\']?([^"\']+)["\']?', line)
                if match:
                    key, value = match.groups()
                    os.environ[key] = value.strip()
                    continue
                
                # åŒ¹é…æ ‡å‡†æ ¼å¼: VAR_NAME=value
                if '=' in line:
                    key, value = line.split('=', 1)
                    key = key.strip()
                    value = value.strip().strip('"').strip("'")
                    os.environ[key] = value
    except Exception as e:
        print(f"âš ï¸ åŠ è½½ç¯å¢ƒå˜é‡æ–‡ä»¶å¤±è´¥: {e}")


# å¯åŠ¨æ—¶è‡ªåŠ¨åŠ è½½ç¯å¢ƒå˜é‡
load_env_file()


# ================= AI å®¢æˆ·ç«¯ç±» =================

class AIClient:
    """
    å¤šæ¨¡æ€ AI å®¢æˆ·ç«¯ï¼Œæ”¯æŒæ–‡æœ¬å’Œå›¾ç‰‡è¾“å…¥
    è‡ªåŠ¨æ£€æµ‹å¯ç”¨çš„ APIï¼ˆä¼˜å…ˆ GitHub GPT-4oï¼Œå…¶æ¬¡ç¡…åŸºæµåŠ¨ï¼‰
    å¯¹äºä¸æ”¯æŒè§†è§‰çš„æ¨¡å‹ï¼Œä½¿ç”¨ OCR + æ–‡æœ¬æ¨¡å‹çš„æ–¹å¼å¤„ç†å›¾ç‰‡
    """
    
    # ç±»å˜é‡ï¼šç¼“å­˜å·²éªŒè¯çš„å®¢æˆ·ç«¯é…ç½®
    _verified_config = None
    _current_model_display = None
    _ocr_config = None  # OCR æ¨¡å‹é…ç½®
    
    # æ”¯æŒè§†è§‰çš„æ¨¡å‹åˆ—è¡¨
    VLM_MODELS = [
        "gpt-4o", "gpt-4-vision", "gpt-4-turbo",
        "qwen-vl", "qwen2-vl", "Qwen2.5-VL",
        "deepseek-vl", "glm-4v",
    ]
    
    def __init__(self, system_prompt: str = "ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„AIåŠ©æ‰‹ã€‚"):
        """
        åˆå§‹åŒ– AI å®¢æˆ·ç«¯ï¼Œè‡ªåŠ¨é€‰æ‹©å¯ç”¨çš„ API
        
        ä¼˜å…ˆçº§ï¼š
        1. SILICONFLOW_API_KEY (ç¡…åŸºæµåŠ¨ - Qwenï¼Œé€Ÿåº¦å¿«)
        2. GITHUB_TOKEN (GitHub Models - GPT-4o)
        """
        self.system_prompt = system_prompt
        
        # å¦‚æœå·²æœ‰éªŒè¯è¿‡çš„é…ç½®ï¼Œç›´æ¥ä½¿ç”¨
        if AIClient._verified_config:
            config = AIClient._verified_config
            self.token = config['token']
            self.endpoint = config['endpoint']
            self.model_name = config['model_name']
            self.is_vlm = config.get('is_vlm', False)
            self.client = OpenAI(base_url=self.endpoint, api_key=self.token)
            return
        
        # é¦–æ¬¡åˆå§‹åŒ–ï¼šæµ‹è¯•å¯ç”¨çš„ API
        self._init_with_test()
    
    def _is_vlm_model(self, model_name: str) -> bool:
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒè§†è§‰ï¼ˆVLMï¼‰"""
        model_lower = model_name.lower()
        for vlm in self.VLM_MODELS:
            if vlm.lower() in model_lower:
                return True
        return False
    
    def _init_with_test(self):
        """æµ‹è¯•å¹¶åˆå§‹åŒ–å¯ç”¨çš„ API"""
        
        # API é…ç½®åˆ—è¡¨ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
        api_configs = []
        # 1. SiliconFlow (å¤‡ç”¨ - Qwen2.5-7B æ˜¯çº¯æ–‡æœ¬æ¨¡å‹)
        if os.environ.get("SILICONFLOW_API_KEY"):
            api_configs.append({
                'name': 'SiliconFlow',
                'token': os.environ.get("SILICONFLOW_API_KEY"),
                'endpoint': "https://api.siliconflow.cn/v1",
                'model_name': "Qwen/Qwen2.5-7B-Instruct",
                'display': "ğŸš€ ç¡…åŸºæµåŠ¨ Qwen2.5-7B + OCR",
                'is_vlm': False
            })
        # 2. GitHub Models (ä¼˜å…ˆ - GPT-4o æ”¯æŒè§†è§‰)
        if os.environ.get("GITHUB_TOKEN"):
            api_configs.append({
                'name': 'GitHub',
                'token': os.environ.get("GITHUB_TOKEN"),
                'endpoint': "https://models.github.ai/inference",
                'model_name': "openai/gpt-4o",
                'display': "ğŸ™ GitHub GPT-4o (VLM)",
                'is_vlm': True
            })

        
        if not api_configs:
            raise ValueError("è¯·è®¾ç½®ç¯å¢ƒå˜é‡: SILICONFLOW_API_KEY æˆ– GITHUB_TOKEN")
        
        # é€ä¸ªæµ‹è¯• API
        for config in api_configs:
            try:
                print(f"ğŸ” æµ‹è¯• {config['name']} API...")
                client = OpenAI(base_url=config['endpoint'], api_key=config['token'])
                
                # å‘é€æµ‹è¯•è¯·æ±‚
                response = client.chat.completions.create(
                    messages=[
                        {"role": "user", "content": "hi"}
                    ],
                    temperature=0.1,
                    max_tokens=5,
                    model=config['model_name']
                )
                
                # æµ‹è¯•æˆåŠŸ
                print(f"âœ… {config['name']} API å¯ç”¨")
                
                self.token = config['token']
                self.endpoint = config['endpoint']
                self.model_name = config['model_name']
                self.is_vlm = config.get('is_vlm', False)
                self.client = client
                
                # ç¼“å­˜é…ç½®
                AIClient._verified_config = config
                AIClient._current_model_display = config['display']
                
                # å¦‚æœä¸æ˜¯ VLMï¼Œåˆå§‹åŒ– OCR é…ç½®
                if not self.is_vlm:
                    self._init_ocr()
                
                return
                
            except Exception as e:
                print(f"âŒ {config['name']} API ä¸å¯ç”¨: {e}")
                continue
        
        raise RuntimeError("æ‰€æœ‰ API å‡ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ– API Key")
    
    def _init_ocr(self):
        """åˆå§‹åŒ– OCR æ¨¡å‹ï¼ˆç”¨äºé VLM æ¨¡å‹å¤„ç†å›¾ç‰‡ï¼‰"""
        # ä½¿ç”¨ç¡…åŸºæµåŠ¨çš„ DeepSeek-OCR
        if os.environ.get("SILICONFLOW_API_KEY"):
            AIClient._ocr_config = {
                'token': os.environ.get("SILICONFLOW_API_KEY"),
                'endpoint': "https://api.siliconflow.cn/v1",
                'model_name': "deepseek-ai/DeepSeek-OCR"
            }
            print("ğŸ“· å·²é…ç½® DeepSeek-OCR ç”¨äºå›¾ç‰‡æ–‡å­—è¯†åˆ«")
        else:
            print("âš ï¸ æœªé…ç½® SILICONFLOW_API_KEYï¼Œå›¾ç‰‡è¯†åˆ«åŠŸèƒ½ä¸å¯ç”¨")
    
    def _ocr_image(self, image) -> str:
        """
        ä½¿ç”¨ OCR æ¨¡å‹è¯†åˆ«å›¾ç‰‡ä¸­çš„æ–‡å­—
        
        :param image: PIL.Image å¯¹è±¡æˆ–å›¾ç‰‡æ–‡ä»¶è·¯å¾„
        :return: è¯†åˆ«å‡ºçš„æ–‡å­—å†…å®¹
        """
        if not AIClient._ocr_config:
            return "[OCR æœªé…ç½®ï¼Œæ— æ³•è¯†åˆ«å›¾ç‰‡å†…å®¹]"
        
        try:
            # è½¬æ¢å›¾ç‰‡ä¸º base64
            data_url = self._image_to_base64(image)
            
            # åˆ›å»º OCR å®¢æˆ·ç«¯
            ocr_client = OpenAI(
                base_url=AIClient._ocr_config['endpoint'],
                api_key=AIClient._ocr_config['token']
            )
            
            # è°ƒç”¨ OCR æ¨¡å‹
            response = ocr_client.chat.completions.create(
                model=AIClient._ocr_config['model_name'],
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": data_url
                                }
                            },
                            {
                                "type": "text",
                                "text": "è¯·è¯†åˆ«å¹¶è¾“å‡ºå›¾ç‰‡ä¸­çš„æ‰€æœ‰æ–‡å­—å†…å®¹ï¼Œä¿æŒåŸæœ‰æ ¼å¼å’Œç»“æ„ã€‚å¦‚æœå›¾ç‰‡ä¸­åŒ…å«å…¬å¼ã€ä»£ç æˆ–è¡¨æ ¼ï¼Œè¯·å°½é‡ä¿æŒå…¶æ ¼å¼ã€‚"
                            }
                        ]
                    }
                ],
                max_tokens=4096
            )
            
            ocr_text = response.choices[0].message.content
            print(f"ğŸ“· OCR è¯†åˆ«å®Œæˆï¼Œè¯†åˆ«åˆ° {len(ocr_text)} å­—ç¬¦")
            print(f"--- OCR è¯†åˆ«å†…å®¹ å¼€å§‹ ---\n{ocr_text}\n--- OCR è¯†åˆ«å†…å®¹ ç»“æŸ ---")
            return ocr_text
            
        except Exception as e:
            print(f"âŒ OCR è¯†åˆ«å¤±è´¥: {e}")
            return f"[OCR è¯†åˆ«å¤±è´¥: {e}]"
    
    @classmethod
    def get_current_model_display(cls) -> str:
        """è·å–å½“å‰ä½¿ç”¨çš„æ¨¡å‹æ˜¾ç¤ºåç§°"""
        return cls._current_model_display or "æœªåˆå§‹åŒ–"
    
    def _image_to_base64(self, image) -> str:
        """
        å°†å›¾ç‰‡è½¬æ¢ä¸º base64 ç¼–ç çš„ data URL
        
        :param image: PIL.Image å¯¹è±¡æˆ–å›¾ç‰‡æ–‡ä»¶è·¯å¾„
        :return: data URL å­—ç¬¦ä¸²
        """
        if isinstance(image, str):
            # å¦‚æœæ˜¯æ–‡ä»¶è·¯å¾„ï¼Œå…ˆåŠ è½½å›¾ç‰‡
            image = Image.open(image)
        
        # è½¬æ¢ä¸º RGB é¿å… RGBA é—®é¢˜
        if image.mode in ('RGBA', 'LA'):
            background = Image.new('RGB', image.size, (255, 255, 255))
            background.paste(image, image.split()[-1] if image.mode == 'RGBA' else None)
            image = background
        elif image.mode != 'RGB':
            image = image.convert('RGB')
        
        buffered = io.BytesIO()
        image.save(buffered, format="JPEG", quality=85)
        img_base64 = base64.b64encode(buffered.getvalue()).decode("utf-8")
        return f"data:image/jpeg;base64,{img_base64}"
    
    def ask(self, text: str = None, image = None, 
            temperature: float = 0.7, max_tokens: int = 2000) -> str:
        """
        å‘ AI å‘é€è¯·æ±‚ï¼Œæ”¯æŒæ–‡æœ¬å’Œ/æˆ–å›¾ç‰‡è¾“å…¥
        
        :param text: æ–‡æœ¬è¾“å…¥ï¼ˆå¯é€‰ï¼‰
        :param image: å›¾ç‰‡è¾“å…¥ï¼Œå¯ä»¥æ˜¯ PIL.Image å¯¹è±¡æˆ–å›¾ç‰‡è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        :param temperature: ç”Ÿæˆæ¸©åº¦ï¼Œæ§åˆ¶éšæœºæ€§
        :param max_tokens: æœ€å¤§ç”Ÿæˆ token æ•°
        :return: AI çš„å›å¤æ–‡æœ¬
        """
        if text is None and image is None:
            raise ValueError("text å’Œ image è‡³å°‘éœ€è¦æä¾›ä¸€ä¸ª")
        
        # å¦‚æœæœ‰å›¾ç‰‡ä½†å½“å‰æ¨¡å‹ä¸æ˜¯ VLMï¼Œä½¿ç”¨ OCR æå–æ–‡å­—
        ocr_text = None
        if image and not getattr(self, 'is_vlm', False):
            print("ğŸ“· å½“å‰æ¨¡å‹ä¸æ”¯æŒè§†è§‰ï¼Œä½¿ç”¨ OCR è¯†åˆ«å›¾ç‰‡...")
            ocr_text = self._ocr_image(image)
            # OCR åä¸å†éœ€è¦å›¾ç‰‡
            image = None
        
        # æ„å»ºç”¨æˆ·æ¶ˆæ¯å†…å®¹
        content = []
        
        # æ·»åŠ åŸå§‹æ–‡æœ¬
        if text:
            content.append({
                "type": "text",
                "text": text
            })
        
        # å¦‚æœæœ‰ OCR è¯†åˆ«çš„æ–‡å­—ï¼Œæ·»åŠ åˆ°å†…å®¹ä¸­
        if ocr_text:
            ocr_prompt = f"\n\nã€å›¾ç‰‡ OCR è¯†åˆ«å†…å®¹ã€‘:\n{ocr_text}\n\nè¯·æ ¹æ®ä»¥ä¸Šå›¾ç‰‡ä¸­è¯†åˆ«å‡ºçš„å†…å®¹è¿›è¡Œåˆ†æå’Œå›ç­”ã€‚"
            if text:
                # è¿½åŠ åˆ°ç°æœ‰æ–‡æœ¬
                content[0]["text"] = text + ocr_prompt
            else:
                # ä½œä¸ºæ–°æ–‡æœ¬
                content.append({
                    "type": "text",
                    "text": ocr_prompt.strip()
                })
        
        # å¦‚æœæ˜¯ VLM ä¸”æœ‰å›¾ç‰‡ï¼Œæ·»åŠ å›¾ç‰‡
        if image and getattr(self, 'is_vlm', False):
            try:
                data_url = self._image_to_base64(image)
                content.append({
                    "type": "image_url",
                    "image_url": {
                        "url": data_url
                    }
                })
            except Exception as e:
                print(f"âš ï¸ å›¾ç‰‡å¤„ç†å¤±è´¥: {e}")
        
        # å¦‚æœåªæœ‰æ–‡æœ¬ï¼Œç®€åŒ–å†…å®¹æ ¼å¼
        if len(content) == 1 and content[0]["type"] == "text":
            user_content = content[0]["text"]
        else:
            user_content = content
        
        try:
            response = self.client.chat.completions.create(
                messages=[
                    {
                        "role": "system",
                        "content": self.system_prompt,
                    },
                    {
                        "role": "user",
                        "content": user_content,
                    }
                ],
                temperature=temperature,
                max_tokens=max_tokens,
                model=self.model_name
            )
            return response.choices[0].message.content
        except Exception as e:
            raise RuntimeError(f"AI è¯·æ±‚å¤±è´¥: {e}")


# ================= ä¾¿æ·å‡½æ•° =================

_default_client = None

def ask_ai(text: str = None, image = None, 
           system_prompt: str = "ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„AIåŠ©æ‰‹ã€‚",
           temperature: float = 0.7, max_tokens: int = 2000) -> str:
    """
    ä¾¿æ·å‡½æ•°ï¼šå‘ AI å‘é€è¯·æ±‚
    
    :param text: æ–‡æœ¬è¾“å…¥ï¼ˆå¯é€‰ï¼‰
    :param image: å›¾ç‰‡è¾“å…¥ï¼Œå¯ä»¥æ˜¯ PIL.Image å¯¹è±¡æˆ–å›¾ç‰‡è·¯å¾„ï¼ˆå¯é€‰ï¼‰
    :param system_prompt: ç³»ç»Ÿæç¤ºè¯
    :param temperature: ç”Ÿæˆæ¸©åº¦
    :param max_tokens: æœ€å¤§ç”Ÿæˆ token æ•°
    :return: AI çš„å›å¤æ–‡æœ¬
    
    ä½¿ç”¨ç¤ºä¾‹:
        from ask_ai import ask_ai
        
        # ä»…æ–‡æœ¬
        response = ask_ai(text="ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ï¼Ÿ")
        
        # ä»…å›¾ç‰‡
        response = ask_ai(image="screenshot.png")
        
        # æ–‡æœ¬ + å›¾ç‰‡
        from PIL import Image
        img = Image.open("chart.png")
        response = ask_ai(text="è§£é‡Šè¿™ä¸ªå›¾è¡¨", image=img)
    """
    global _default_client
    
    if _default_client is None or _default_client.system_prompt != system_prompt:
        _default_client = AIClient(system_prompt=system_prompt)
    
    return _default_client.ask(text=text, image=image, 
                                temperature=temperature, max_tokens=max_tokens)


# ================= æµ‹è¯•å…¥å£ =================

if __name__ == "__main__":
    # ç®€å•æµ‹è¯•
    try:
        print("=" * 50)
        print("ğŸ”§ AI å®¢æˆ·ç«¯åˆå§‹åŒ–æµ‹è¯•")
        print("=" * 50)
        
        client = AIClient()
        print(f"\nâœ… åˆå§‹åŒ–æˆåŠŸï¼å½“å‰æ¨¡å‹: {AIClient.get_current_model_display()}")
        print(f"   æ˜¯å¦ VLM: {client.is_vlm}")
        
        # æµ‹è¯•çº¯æ–‡æœ¬
        print("\n--- æµ‹è¯•çº¯æ–‡æœ¬ ---")
        response = client.ask(text="ç”¨ä¸€å¥è¯ä»‹ç»ä»€ä¹ˆæ˜¯GAN", max_tokens=100)
        print(f"å›å¤: {response}")
        
        # å¦‚æœæœ‰ OCR é…ç½®ï¼Œæµ‹è¯• OCR åŠŸèƒ½
        if AIClient._ocr_config:
            print("\n--- OCR é…ç½®å·²å°±ç»ª ---")
            print(f"OCR æ¨¡å‹: {AIClient._ocr_config['model_name']}")
        
    except ValueError as e:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
    except Exception as e:
        print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")